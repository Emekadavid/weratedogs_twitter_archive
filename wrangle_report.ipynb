{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report on the data wrangling activity "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I first considered data quality issues. Data quality issues are problems with the content of the data. They could involve missing data or duplicated data. \n",
    "I created three data frames for the data, namely:\n",
    "\n",
    "1.\tTwitter_archive: These contained data from the WeRateDogs twitter archive. \n",
    "\n",
    "2.\tImage_predictions: These contained links to image posts on the twitter archive and the predictions by a neural network of what dogs the posts were referring to. \n",
    "\n",
    "3.\tCounts_tweet: these contained data for the retweet and favorite count of the twitter archive data based on the tweet IDs. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It was discovered that the data has several quality issues. \n",
    "\n",
    "For example, the timestamps for the twitter_archive dataframe were unecessary. After deliberating on this, I decided to remove it. I know that all my tweet IDs were for 2017 tweets. The source column in this dataframe had its actual values embedded in the inner texts of html tags. I had to extract the actual source texts from the tags to make it usable. Also, since the analysis were based on original tweets and I don’t want any retweets, then I had to remove the rows that had retweets and then remove the retweets related columns after removing their rows. Still, on this data frame, there was a column, expanded_urls, with links to the image posts. Since I already had a data frame containing this information, this column was unnecessary. These are some of the quality issues I found in this dataframe. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the image prediction dataframe, some of the quality issues I found were that the jgp_url were unique links that needed to be revised. So, I decided they had to be removed. I also had to melt the predictions by the neural networks for the dog images. I decided that if the highest prediction were a dog breed, I would use that. Otherwise, I would check the next highest and the third highest. And if none of these three predictions were a dog breed, then I would insert the string “not a dog” in the melted column. \n",
    "\n",
    "As for the counts’ tweet, the only quality issue I found was with the tweet_id column. I realized that it was encoded as a string. I had to change it to the int64 data type. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next issue addressed was the tidiness issue. Tidiness issues are data that have problems with the structure. Maybe a single variable was spread across more than one column, and they had to be melted, or the table was not a unique entity and had to be merged with another table because information were for the same entity. \n",
    "\n",
    "The tidiness issue for the twitter_archive data frame was that the dog stages, “doggo”, “floofer”, “pupper”, and “Puppo” were spread across four columns when it was supposed to be one variable name dog_stage. So, I had to melt these four columns and make them one variable. The same issue and resolution were done for the dog_names in the image_predictions data frame. Then all three data frames were merged to make one master data frame because they were on a single entity, dog ratings. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
